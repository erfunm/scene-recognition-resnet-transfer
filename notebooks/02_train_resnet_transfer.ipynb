{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876d7caf",
   "metadata": {},
   "source": [
    "# 02 â€” Train ResNet (Transfer Learning)\n",
    "\n",
    "Fine-tune a ResNet-34 or ResNet-50 backbone using **dual learning rates** (smaller LR on pretrained backbone,\n",
    "larger LR on the new classification head), with **StepLR** schedule, **early stopping**, and **best-model saving**.\n",
    "We log **top-1**, **top-5**, **F1 (macro)**, and **mAP**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3859e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install numpy pandas scikit-learn matplotlib tqdm\n",
    "\n",
    "import os, json, time, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "from sklearn.metrics import f1_score, average_precision_score, top_k_accuracy_score\n",
    "\n",
    "DATA_ROOT = Path(\"/path/to/Places2_simp\")  # <-- EDIT\n",
    "SAVE_DIR = Path(\"../checkpoints\"); SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NUM_WORKERS = 4\n",
    "BATCH_TRAIN, BATCH_VAL = 256, 1024\n",
    "\n",
    "CFG = {\n",
    "    \"arch\": \"resnet34\",      # 'resnet34' or 'resnet50'\n",
    "    \"epochs\": 30,\n",
    "    \"patience\": 10,\n",
    "    \"lr_backbone\": 1e-4,\n",
    "    \"lr_head\": 1e-3,\n",
    "    \"weight_decay\": 8e-4,\n",
    "    \"step_size\": 6,\n",
    "    \"gamma\": 0.6,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "print(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75973a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=20, fill=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "bare = datasets.ImageFolder(root=str(DATA_ROOT))\n",
    "targets = np.array([y for _, y in bare.imgs])\n",
    "num_classes = len(bare.classes)\n",
    "\n",
    "train_idx, val_idx = [], []\n",
    "for cls, idxs in pd.Series(np.arange(len(targets))).groupby(targets).groups.items():\n",
    "    idxs = np.array(list(idxs)); np.random.shuffle(idxs); n_val = int(0.2*len(idxs))\n",
    "    val_idx.extend(idxs[:n_val]); train_idx.extend(idxs[n_val:])\n",
    "\n",
    "train_ds = Subset(datasets.ImageFolder(root=str(DATA_ROOT), transform=train_tf), train_idx)\n",
    "val_ds   = Subset(datasets.ImageFolder(root=str(DATA_ROOT), transform=val_tf), val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_VAL,   shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b260cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(arch, num_classes):\n",
    "    if arch == \"resnet34\":\n",
    "        m = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "    elif arch == \"resnet50\":\n",
    "        m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    else:\n",
    "        raise ValueError(\"arch must be resnet34 or resnet50\")\n",
    "    in_features = m.fc.in_features\n",
    "    m.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_features, num_classes))\n",
    "    return m\n",
    "\n",
    "model = build_model(CFG[\"arch\"], num_classes).to(CFG[\"device\"])\n",
    "backbone_params, head_params = [], []\n",
    "for name, p in model.named_parameters():\n",
    "    (head_params if name.startswith(\"fc.\") else backbone_params).append(p)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": CFG[\"lr_backbone\"]},\n",
    "    {\"params\": head_params,     \"lr\": CFG[\"lr_head\"]}\n",
    "], weight_decay=CFG[\"weight_decay\"])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=CFG[\"step_size\"], gamma=CFG[\"gamma\"])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b123875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(loader, train=True):\n",
    "    model.train(train)\n",
    "    loss_sum, y_true, y_prob = 0.0, [], []\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(CFG[\"device\"]), y.to(CFG[\"device\"])\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(x); loss = criterion(logits, y)\n",
    "            if train: optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        loss_sum += float(loss.detach().cpu()) * y.size(0)\n",
    "        y_true.append(y.detach().cpu().numpy())\n",
    "        y_prob.append(torch.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "    y_true = np.concatenate(y_true); y_prob = np.concatenate(y_prob)\n",
    "    y_pred = y_prob.argmax(1)\n",
    "    top1 = (y_pred == y_true).mean()\n",
    "    top5 = top_k_accuracy_score(y_true, y_prob, k=5, labels=np.arange(num_classes))\n",
    "    f1   = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    y_true_ovr = np.eye(num_classes)[y_true]\n",
    "    mAP  = average_precision_score(y_true_ovr, y_prob, average=\"macro\")\n",
    "    return loss_sum/len(loader.dataset), top1, top5, f1, mAP\n",
    "\n",
    "best_val_loss = float(\"inf\"); patience = 0; history=[]\n",
    "for epoch in range(1, CFG[\"epochs\"]+1):\n",
    "    tr = epoch_run(train_loader, True)\n",
    "    va = epoch_run(val_loader, False)\n",
    "    scheduler.step()\n",
    "    history.append({\"epoch\":epoch, \"train_loss\":tr[0], \"val_loss\":va[0],\n",
    "                    \"train_top1\":tr[1], \"val_top1\":va[1],\n",
    "                    \"train_top5\":tr[2], \"val_top5\":va[2],\n",
    "                    \"train_f1\":tr[3],   \"val_f1\":va[3],\n",
    "                    \"train_mAP\":tr[4],  \"val_mAP\":va[4]})\n",
    "    print(f\"Epoch {epoch:02d} | tr loss {tr[0]:.4f} top1 {tr[1]*100:.2f} top5 {tr[2]*100:.2f} | \"\n",
    "          f\"va loss {va[0]:.4f} top1 {va[1]*100:.2f} top5 {va[2]*100:.2f} f1 {va[3]:.3f} mAP {va[4]:.3f}\")\n",
    "    if va[0] < best_val_loss:\n",
    "        best_val_loss = va[0]; patience = 0\n",
    "        torch.save(model.state_dict(), SAVE_DIR / f\"best_{CFG['arch']}.pth\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= CFG[\"patience\"]:\n",
    "            print(\"Early stopping.\"); break\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "hist_df.to_csv(SAVE_DIR / f\"history_{CFG['arch']}.csv\", index=False)\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "ax[0].plot(hist_df['epoch'], hist_df['train_loss'], label='train'); ax[0].plot(hist_df['epoch'], hist_df['val_loss'], label='val'); ax[0].set_title('Loss'); ax[0].legend()\n",
    "ax[1].plot(hist_df['epoch'], hist_df['val_top1']*100, label='Top-1'); ax[1].plot(hist_df['epoch'], hist_df['val_top5']*100, label='Top-5'); ax[1].set_title('Accuracies'); ax[1].legend()\n",
    "plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
